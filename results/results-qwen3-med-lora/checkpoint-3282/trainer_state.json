{
  "best_global_step": 3200,
  "best_metric": 0.996751070022583,
  "best_model_checkpoint": "./results-qwen3-med-lora/checkpoint-3200",
  "epoch": 1.0,
  "eval_steps": 100,
  "global_step": 3282,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0060947737315252175,
      "grad_norm": 2.184260368347168,
      "learning_rate": 1.1515151515151517e-05,
      "loss": 2.3511,
      "step": 20
    },
    {
      "epoch": 0.012189547463050435,
      "grad_norm": 1.2929558753967285,
      "learning_rate": 2.3636363636363637e-05,
      "loss": 1.9884,
      "step": 40
    },
    {
      "epoch": 0.01828432119457565,
      "grad_norm": 0.5868825912475586,
      "learning_rate": 3.575757575757576e-05,
      "loss": 1.6006,
      "step": 60
    },
    {
      "epoch": 0.02437909492610087,
      "grad_norm": 0.6876945495605469,
      "learning_rate": 4.787878787878788e-05,
      "loss": 1.3454,
      "step": 80
    },
    {
      "epoch": 0.030473868657626087,
      "grad_norm": 0.4796135425567627,
      "learning_rate": 6e-05,
      "loss": 1.2619,
      "step": 100
    },
    {
      "epoch": 0.030473868657626087,
      "eval_loss": 1.1997551918029785,
      "eval_runtime": 239.0716,
      "eval_samples_per_second": 13.728,
      "eval_steps_per_second": 1.719,
      "step": 100
    },
    {
      "epoch": 0.0365686423891513,
      "grad_norm": 0.7338961958885193,
      "learning_rate": 7.212121212121213e-05,
      "loss": 1.1934,
      "step": 120
    },
    {
      "epoch": 0.04266341612067652,
      "grad_norm": 0.845910906791687,
      "learning_rate": 8.424242424242424e-05,
      "loss": 1.0984,
      "step": 140
    },
    {
      "epoch": 0.04875818985220174,
      "grad_norm": 1.0811693668365479,
      "learning_rate": 9.636363636363637e-05,
      "loss": 1.1436,
      "step": 160
    },
    {
      "epoch": 0.05485296358372695,
      "grad_norm": 0.5665521025657654,
      "learning_rate": 9.999502245706303e-05,
      "loss": 1.1741,
      "step": 180
    },
    {
      "epoch": 0.06094773731525217,
      "grad_norm": 0.6340416669845581,
      "learning_rate": 9.997064504064689e-05,
      "loss": 1.107,
      "step": 200
    },
    {
      "epoch": 0.06094773731525217,
      "eval_loss": 1.1074777841567993,
      "eval_runtime": 239.0972,
      "eval_samples_per_second": 13.727,
      "eval_steps_per_second": 1.719,
      "step": 200
    },
    {
      "epoch": 0.06704251104677739,
      "grad_norm": 0.5141214728355408,
      "learning_rate": 9.992596340089365e-05,
      "loss": 1.1129,
      "step": 220
    },
    {
      "epoch": 0.0731372847783026,
      "grad_norm": 1.2434511184692383,
      "learning_rate": 9.986099569298204e-05,
      "loss": 1.1966,
      "step": 240
    },
    {
      "epoch": 0.07923205850982783,
      "grad_norm": 0.5612601637840271,
      "learning_rate": 9.977576831478724e-05,
      "loss": 1.0376,
      "step": 260
    },
    {
      "epoch": 0.08532683224135304,
      "grad_norm": 0.5571919083595276,
      "learning_rate": 9.967031589615486e-05,
      "loss": 1.2437,
      "step": 280
    },
    {
      "epoch": 0.09142160597287825,
      "grad_norm": 0.6422864198684692,
      "learning_rate": 9.954468128482995e-05,
      "loss": 1.102,
      "step": 300
    },
    {
      "epoch": 0.09142160597287825,
      "eval_loss": 1.092971920967102,
      "eval_runtime": 239.0775,
      "eval_samples_per_second": 13.728,
      "eval_steps_per_second": 1.719,
      "step": 300
    },
    {
      "epoch": 0.09751637970440348,
      "grad_norm": 0.5066696405410767,
      "learning_rate": 9.939891552904701e-05,
      "loss": 1.0172,
      "step": 320
    },
    {
      "epoch": 0.1036111534359287,
      "grad_norm": 0.35161104798316956,
      "learning_rate": 9.923307785678797e-05,
      "loss": 1.0567,
      "step": 340
    },
    {
      "epoch": 0.1097059271674539,
      "grad_norm": 0.3519589304924011,
      "learning_rate": 9.904723565171643e-05,
      "loss": 1.0272,
      "step": 360
    },
    {
      "epoch": 0.11580070089897912,
      "grad_norm": 0.6482990980148315,
      "learning_rate": 9.884146442579816e-05,
      "loss": 1.1133,
      "step": 380
    },
    {
      "epoch": 0.12189547463050435,
      "grad_norm": 0.6777237057685852,
      "learning_rate": 9.861584778861878e-05,
      "loss": 1.025,
      "step": 400
    },
    {
      "epoch": 0.12189547463050435,
      "eval_loss": 1.0773119926452637,
      "eval_runtime": 239.1473,
      "eval_samples_per_second": 13.724,
      "eval_steps_per_second": 1.719,
      "step": 400
    },
    {
      "epoch": 0.12799024836202955,
      "grad_norm": 0.5720539689064026,
      "learning_rate": 9.837047741341141e-05,
      "loss": 1.1314,
      "step": 420
    },
    {
      "epoch": 0.13408502209355477,
      "grad_norm": 0.42782309651374817,
      "learning_rate": 9.81054529998076e-05,
      "loss": 1.014,
      "step": 440
    },
    {
      "epoch": 0.14017979582508,
      "grad_norm": 0.5563042759895325,
      "learning_rate": 9.782088223332706e-05,
      "loss": 0.9662,
      "step": 460
    },
    {
      "epoch": 0.1462745695566052,
      "grad_norm": 0.4295535087585449,
      "learning_rate": 9.751688074162268e-05,
      "loss": 1.1287,
      "step": 480
    },
    {
      "epoch": 0.15236934328813043,
      "grad_norm": 0.4375348389148712,
      "learning_rate": 9.719357204749824e-05,
      "loss": 1.1456,
      "step": 500
    },
    {
      "epoch": 0.15236934328813043,
      "eval_loss": 1.0656458139419556,
      "eval_runtime": 238.7094,
      "eval_samples_per_second": 13.749,
      "eval_steps_per_second": 1.722,
      "step": 500
    },
    {
      "epoch": 0.15846411701965565,
      "grad_norm": 0.5941838026046753,
      "learning_rate": 9.68510875187183e-05,
      "loss": 1.12,
      "step": 520
    },
    {
      "epoch": 0.16455889075118085,
      "grad_norm": 0.4377765357494354,
      "learning_rate": 9.648956631463042e-05,
      "loss": 1.0871,
      "step": 540
    },
    {
      "epoch": 0.17065366448270608,
      "grad_norm": 0.5259969830513,
      "learning_rate": 9.610915532962156e-05,
      "loss": 0.8125,
      "step": 560
    },
    {
      "epoch": 0.1767484382142313,
      "grad_norm": 0.7539556622505188,
      "learning_rate": 9.571000913343148e-05,
      "loss": 0.9771,
      "step": 580
    },
    {
      "epoch": 0.1828432119457565,
      "grad_norm": 0.43182480335235596,
      "learning_rate": 9.529228990834751e-05,
      "loss": 1.0764,
      "step": 600
    },
    {
      "epoch": 0.1828432119457565,
      "eval_loss": 1.0589876174926758,
      "eval_runtime": 238.6,
      "eval_samples_per_second": 13.755,
      "eval_steps_per_second": 1.723,
      "step": 600
    },
    {
      "epoch": 0.18893798567728173,
      "grad_norm": 0.6863086223602295,
      "learning_rate": 9.485616738330611e-05,
      "loss": 1.0903,
      "step": 620
    },
    {
      "epoch": 0.19503275940880696,
      "grad_norm": 0.6142813563346863,
      "learning_rate": 9.44018187649282e-05,
      "loss": 1.0705,
      "step": 640
    },
    {
      "epoch": 0.20112753314033216,
      "grad_norm": 0.5611832737922668,
      "learning_rate": 9.39294286655159e-05,
      "loss": 0.9364,
      "step": 660
    },
    {
      "epoch": 0.2072223068718574,
      "grad_norm": 0.41574332118034363,
      "learning_rate": 9.343918902804038e-05,
      "loss": 1.1001,
      "step": 680
    },
    {
      "epoch": 0.2133170806033826,
      "grad_norm": 0.5118028521537781,
      "learning_rate": 9.293129904815101e-05,
      "loss": 1.0914,
      "step": 700
    },
    {
      "epoch": 0.2133170806033826,
      "eval_loss": 1.0515129566192627,
      "eval_runtime": 238.8372,
      "eval_samples_per_second": 13.742,
      "eval_steps_per_second": 1.721,
      "step": 700
    },
    {
      "epoch": 0.2194118543349078,
      "grad_norm": 0.6761088371276855,
      "learning_rate": 9.240596509323755e-05,
      "loss": 1.0002,
      "step": 720
    },
    {
      "epoch": 0.22550662806643304,
      "grad_norm": 0.3726135194301605,
      "learning_rate": 9.186340061857839e-05,
      "loss": 1.0911,
      "step": 740
    },
    {
      "epoch": 0.23160140179795824,
      "grad_norm": 0.43078118562698364,
      "learning_rate": 9.130382608060868e-05,
      "loss": 0.9303,
      "step": 760
    },
    {
      "epoch": 0.23769617552948347,
      "grad_norm": 0.5007448196411133,
      "learning_rate": 9.072746884734384e-05,
      "loss": 1.104,
      "step": 780
    },
    {
      "epoch": 0.2437909492610087,
      "grad_norm": 0.8337869644165039,
      "learning_rate": 9.013456310599472e-05,
      "loss": 0.8907,
      "step": 800
    },
    {
      "epoch": 0.2437909492610087,
      "eval_loss": 1.0463556051254272,
      "eval_runtime": 238.6064,
      "eval_samples_per_second": 13.755,
      "eval_steps_per_second": 1.723,
      "step": 800
    },
    {
      "epoch": 0.2498857229925339,
      "grad_norm": 0.606356680393219,
      "learning_rate": 8.952534976781193e-05,
      "loss": 1.015,
      "step": 820
    },
    {
      "epoch": 0.2559804967240591,
      "grad_norm": 0.7779578566551208,
      "learning_rate": 8.890007637019804e-05,
      "loss": 0.9999,
      "step": 840
    },
    {
      "epoch": 0.2620752704555843,
      "grad_norm": 0.49353501200675964,
      "learning_rate": 8.825899697612745e-05,
      "loss": 1.0772,
      "step": 860
    },
    {
      "epoch": 0.26817004418710955,
      "grad_norm": 0.7053182721138,
      "learning_rate": 8.760237207091476e-05,
      "loss": 1.1152,
      "step": 880
    },
    {
      "epoch": 0.2742648179186348,
      "grad_norm": 0.5951864123344421,
      "learning_rate": 8.693046845637358e-05,
      "loss": 1.1013,
      "step": 900
    },
    {
      "epoch": 0.2742648179186348,
      "eval_loss": 1.0409512519836426,
      "eval_runtime": 238.6045,
      "eval_samples_per_second": 13.755,
      "eval_steps_per_second": 1.723,
      "step": 900
    },
    {
      "epoch": 0.28035959165016,
      "grad_norm": 0.5428699851036072,
      "learning_rate": 8.624355914240884e-05,
      "loss": 0.958,
      "step": 920
    },
    {
      "epoch": 0.2864543653816852,
      "grad_norm": 0.5235821604728699,
      "learning_rate": 8.55419232360865e-05,
      "loss": 1.0126,
      "step": 940
    },
    {
      "epoch": 0.2925491391132104,
      "grad_norm": 0.49361515045166016,
      "learning_rate": 8.482584582822601e-05,
      "loss": 1.1608,
      "step": 960
    },
    {
      "epoch": 0.2986439128447356,
      "grad_norm": 0.4050510823726654,
      "learning_rate": 8.409561787756136e-05,
      "loss": 1.1351,
      "step": 980
    },
    {
      "epoch": 0.30473868657626085,
      "grad_norm": 0.4393545687198639,
      "learning_rate": 8.335153609251776e-05,
      "loss": 1.0221,
      "step": 1000
    },
    {
      "epoch": 0.30473868657626085,
      "eval_loss": 1.0351349115371704,
      "eval_runtime": 238.599,
      "eval_samples_per_second": 13.755,
      "eval_steps_per_second": 1.723,
      "step": 1000
    },
    {
      "epoch": 0.3108334603077861,
      "grad_norm": 0.5032346844673157,
      "learning_rate": 8.25939028106522e-05,
      "loss": 1.052,
      "step": 1020
    },
    {
      "epoch": 0.3169282340393113,
      "grad_norm": 0.8122484087944031,
      "learning_rate": 8.182302587580685e-05,
      "loss": 1.108,
      "step": 1040
    },
    {
      "epoch": 0.32302300777083653,
      "grad_norm": 0.4642026126384735,
      "learning_rate": 8.103921851302486e-05,
      "loss": 1.1397,
      "step": 1060
    },
    {
      "epoch": 0.3291177815023617,
      "grad_norm": 0.6980361342430115,
      "learning_rate": 8.024279920127993e-05,
      "loss": 0.9861,
      "step": 1080
    },
    {
      "epoch": 0.33521255523388693,
      "grad_norm": 0.3503687083721161,
      "learning_rate": 7.943409154407092e-05,
      "loss": 1.1588,
      "step": 1100
    },
    {
      "epoch": 0.33521255523388693,
      "eval_loss": 1.0309828519821167,
      "eval_runtime": 238.5571,
      "eval_samples_per_second": 13.758,
      "eval_steps_per_second": 1.723,
      "step": 1100
    },
    {
      "epoch": 0.34130732896541216,
      "grad_norm": 0.8083942532539368,
      "learning_rate": 7.861342413793433e-05,
      "loss": 0.964,
      "step": 1120
    },
    {
      "epoch": 0.3474021026969374,
      "grad_norm": 0.5817225575447083,
      "learning_rate": 7.778113043892792e-05,
      "loss": 1.1165,
      "step": 1140
    },
    {
      "epoch": 0.3534968764284626,
      "grad_norm": 0.6658313274383545,
      "learning_rate": 7.693754862713986e-05,
      "loss": 1.1017,
      "step": 1160
    },
    {
      "epoch": 0.3595916501599878,
      "grad_norm": 0.518315315246582,
      "learning_rate": 7.608302146927846e-05,
      "loss": 1.0319,
      "step": 1180
    },
    {
      "epoch": 0.365686423891513,
      "grad_norm": 0.6557015180587769,
      "learning_rate": 7.521789617939797e-05,
      "loss": 1.0248,
      "step": 1200
    },
    {
      "epoch": 0.365686423891513,
      "eval_loss": 1.0284061431884766,
      "eval_runtime": 238.5751,
      "eval_samples_per_second": 13.757,
      "eval_steps_per_second": 1.723,
      "step": 1200
    },
    {
      "epoch": 0.37178119762303824,
      "grad_norm": 0.8040482997894287,
      "learning_rate": 7.434252427781772e-05,
      "loss": 1.1066,
      "step": 1220
    },
    {
      "epoch": 0.37787597135456347,
      "grad_norm": 0.5016240477561951,
      "learning_rate": 7.345726144829117e-05,
      "loss": 1.0201,
      "step": 1240
    },
    {
      "epoch": 0.3839707450860887,
      "grad_norm": 0.5203083753585815,
      "learning_rate": 7.256246739348356e-05,
      "loss": 0.953,
      "step": 1260
    },
    {
      "epoch": 0.3900655188176139,
      "grad_norm": 0.3282564878463745,
      "learning_rate": 7.16585056888163e-05,
      "loss": 1.1056,
      "step": 1280
    },
    {
      "epoch": 0.3961602925491391,
      "grad_norm": 0.5338346362113953,
      "learning_rate": 7.074574363473798e-05,
      "loss": 0.9425,
      "step": 1300
    },
    {
      "epoch": 0.3961602925491391,
      "eval_loss": 1.024609923362732,
      "eval_runtime": 238.7114,
      "eval_samples_per_second": 13.749,
      "eval_steps_per_second": 1.722,
      "step": 1300
    },
    {
      "epoch": 0.4022550662806643,
      "grad_norm": 0.5383616089820862,
      "learning_rate": 6.982455210748172e-05,
      "loss": 0.9909,
      "step": 1320
    },
    {
      "epoch": 0.40834984001218955,
      "grad_norm": 0.6478572487831116,
      "learning_rate": 6.889530540836965e-05,
      "loss": 1.1697,
      "step": 1340
    },
    {
      "epoch": 0.4144446137437148,
      "grad_norm": 0.42637625336647034,
      "learning_rate": 6.795838111172561e-05,
      "loss": 1.0352,
      "step": 1360
    },
    {
      "epoch": 0.42053938747524,
      "grad_norm": 3.054715394973755,
      "learning_rate": 6.701415991145808e-05,
      "loss": 1.0573,
      "step": 1380
    },
    {
      "epoch": 0.4266341612067652,
      "grad_norm": 0.44056612253189087,
      "learning_rate": 6.606302546637542e-05,
      "loss": 1.028,
      "step": 1400
    },
    {
      "epoch": 0.4266341612067652,
      "eval_loss": 1.0209485292434692,
      "eval_runtime": 238.6462,
      "eval_samples_per_second": 13.753,
      "eval_steps_per_second": 1.722,
      "step": 1400
    },
    {
      "epoch": 0.4327289349382904,
      "grad_norm": 0.46940064430236816,
      "learning_rate": 6.510536424429652e-05,
      "loss": 0.9744,
      "step": 1420
    },
    {
      "epoch": 0.4388237086698156,
      "grad_norm": 0.5378671288490295,
      "learning_rate": 6.414156536501997e-05,
      "loss": 0.9642,
      "step": 1440
    },
    {
      "epoch": 0.44491848240134085,
      "grad_norm": 0.6694266200065613,
      "learning_rate": 6.317202044221579e-05,
      "loss": 1.0029,
      "step": 1460
    },
    {
      "epoch": 0.4510132561328661,
      "grad_norm": 0.7297621369361877,
      "learning_rate": 6.219712342430371e-05,
      "loss": 1.031,
      "step": 1480
    },
    {
      "epoch": 0.4571080298643913,
      "grad_norm": 0.6693148016929626,
      "learning_rate": 6.121727043438297e-05,
      "loss": 1.0251,
      "step": 1500
    },
    {
      "epoch": 0.4571080298643913,
      "eval_loss": 1.017803430557251,
      "eval_runtime": 238.9358,
      "eval_samples_per_second": 13.736,
      "eval_steps_per_second": 1.72,
      "step": 1500
    },
    {
      "epoch": 0.4632028035959165,
      "grad_norm": 0.3923719525337219,
      "learning_rate": 6.023285960927824e-05,
      "loss": 0.9242,
      "step": 1520
    },
    {
      "epoch": 0.4692975773274417,
      "grad_norm": 0.5084456205368042,
      "learning_rate": 5.924429093776757e-05,
      "loss": 0.8737,
      "step": 1540
    },
    {
      "epoch": 0.47539235105896693,
      "grad_norm": 0.9110203981399536,
      "learning_rate": 5.825196609805774e-05,
      "loss": 1.104,
      "step": 1560
    },
    {
      "epoch": 0.48148712479049216,
      "grad_norm": 0.4389016330242157,
      "learning_rate": 5.725628829457309e-05,
      "loss": 1.0352,
      "step": 1580
    },
    {
      "epoch": 0.4875818985220174,
      "grad_norm": 0.536072313785553,
      "learning_rate": 5.625766209412435e-05,
      "loss": 1.1249,
      "step": 1600
    },
    {
      "epoch": 0.4875818985220174,
      "eval_loss": 1.0152957439422607,
      "eval_runtime": 238.6935,
      "eval_samples_per_second": 13.75,
      "eval_steps_per_second": 1.722,
      "step": 1600
    },
    {
      "epoch": 0.4936766722535426,
      "grad_norm": 0.6905620098114014,
      "learning_rate": 5.525649326152381e-05,
      "loss": 1.0616,
      "step": 1620
    },
    {
      "epoch": 0.4997714459850678,
      "grad_norm": 0.5278828740119934,
      "learning_rate": 5.425318859471369e-05,
      "loss": 1.0428,
      "step": 1640
    },
    {
      "epoch": 0.5058662197165931,
      "grad_norm": 0.5358002781867981,
      "learning_rate": 5.3248155759474846e-05,
      "loss": 1.0007,
      "step": 1660
    },
    {
      "epoch": 0.5119609934481182,
      "grad_norm": 0.695642352104187,
      "learning_rate": 5.224180312378277e-05,
      "loss": 1.0183,
      "step": 1680
    },
    {
      "epoch": 0.5180557671796434,
      "grad_norm": 0.6165861487388611,
      "learning_rate": 5.123453959187818e-05,
      "loss": 1.0291,
      "step": 1700
    },
    {
      "epoch": 0.5180557671796434,
      "eval_loss": 1.013060212135315,
      "eval_runtime": 238.6622,
      "eval_samples_per_second": 13.752,
      "eval_steps_per_second": 1.722,
      "step": 1700
    },
    {
      "epoch": 0.5241505409111686,
      "grad_norm": 0.6695881485939026,
      "learning_rate": 5.022677443811999e-05,
      "loss": 1.0513,
      "step": 1720
    },
    {
      "epoch": 0.5302453146426939,
      "grad_norm": 0.8633792996406555,
      "learning_rate": 4.9218917140687535e-05,
      "loss": 1.0265,
      "step": 1740
    },
    {
      "epoch": 0.5363400883742191,
      "grad_norm": 0.39533567428588867,
      "learning_rate": 4.8211377215200295e-05,
      "loss": 0.8457,
      "step": 1760
    },
    {
      "epoch": 0.5424348621057443,
      "grad_norm": 0.8808783888816833,
      "learning_rate": 4.720456404832223e-05,
      "loss": 1.0886,
      "step": 1780
    },
    {
      "epoch": 0.5485296358372695,
      "grad_norm": 0.696067750453949,
      "learning_rate": 4.619888673141849e-05,
      "loss": 0.9695,
      "step": 1800
    },
    {
      "epoch": 0.5485296358372695,
      "eval_loss": 1.0108447074890137,
      "eval_runtime": 238.6485,
      "eval_samples_per_second": 13.752,
      "eval_steps_per_second": 1.722,
      "step": 1800
    },
    {
      "epoch": 0.5546244095687948,
      "grad_norm": 0.7049421072006226,
      "learning_rate": 4.5194753894332305e-05,
      "loss": 1.0153,
      "step": 1820
    },
    {
      "epoch": 0.56071918330032,
      "grad_norm": 0.5452997088432312,
      "learning_rate": 4.419257353934915e-05,
      "loss": 1.0301,
      "step": 1840
    },
    {
      "epoch": 0.5668139570318452,
      "grad_norm": 0.7024238705635071,
      "learning_rate": 4.3192752875416126e-05,
      "loss": 0.972,
      "step": 1860
    },
    {
      "epoch": 0.5729087307633705,
      "grad_norm": 0.7328609228134155,
      "learning_rate": 4.219569815268349e-05,
      "loss": 1.0755,
      "step": 1880
    },
    {
      "epoch": 0.5790035044948957,
      "grad_norm": 0.5922235250473022,
      "learning_rate": 4.120181449743597e-05,
      "loss": 1.1171,
      "step": 1900
    },
    {
      "epoch": 0.5790035044948957,
      "eval_loss": 1.0083692073822021,
      "eval_runtime": 238.7404,
      "eval_samples_per_second": 13.747,
      "eval_steps_per_second": 1.722,
      "step": 1900
    },
    {
      "epoch": 0.5850982782264208,
      "grad_norm": 0.9667710661888123,
      "learning_rate": 4.0211505747480535e-05,
      "loss": 1.0359,
      "step": 1920
    },
    {
      "epoch": 0.591193051957946,
      "grad_norm": 0.8267260193824768,
      "learning_rate": 3.9225174288057895e-05,
      "loss": 0.9556,
      "step": 1940
    },
    {
      "epoch": 0.5972878256894713,
      "grad_norm": 0.6489996314048767,
      "learning_rate": 3.824322088834402e-05,
      "loss": 1.1623,
      "step": 1960
    },
    {
      "epoch": 0.6033825994209965,
      "grad_norm": 0.4698229730129242,
      "learning_rate": 3.726604453860845e-05,
      "loss": 0.9486,
      "step": 1980
    },
    {
      "epoch": 0.6094773731525217,
      "grad_norm": 0.6242355704307556,
      "learning_rate": 3.629404228809542e-05,
      "loss": 1.0737,
      "step": 2000
    },
    {
      "epoch": 0.6094773731525217,
      "eval_loss": 1.0063543319702148,
      "eval_runtime": 239.0826,
      "eval_samples_per_second": 13.727,
      "eval_steps_per_second": 1.719,
      "step": 2000
    },
    {
      "epoch": 0.6155721468840469,
      "grad_norm": 0.6731576919555664,
      "learning_rate": 3.532760908369344e-05,
      "loss": 1.0257,
      "step": 2020
    },
    {
      "epoch": 0.6216669206155722,
      "grad_norm": 0.4741084575653076,
      "learning_rate": 3.43671376094595e-05,
      "loss": 1.1041,
      "step": 2040
    },
    {
      "epoch": 0.6277616943470974,
      "grad_norm": 0.6991609334945679,
      "learning_rate": 3.341301812706229e-05,
      "loss": 0.9407,
      "step": 2060
    },
    {
      "epoch": 0.6338564680786226,
      "grad_norm": 0.7144471406936646,
      "learning_rate": 3.2465638317210126e-05,
      "loss": 1.021,
      "step": 2080
    },
    {
      "epoch": 0.6399512418101478,
      "grad_norm": 0.5983479022979736,
      "learning_rate": 3.152538312212708e-05,
      "loss": 0.9645,
      "step": 2100
    },
    {
      "epoch": 0.6399512418101478,
      "eval_loss": 1.0047321319580078,
      "eval_runtime": 238.8015,
      "eval_samples_per_second": 13.744,
      "eval_steps_per_second": 1.721,
      "step": 2100
    },
    {
      "epoch": 0.6460460155416731,
      "grad_norm": 0.7998424172401428,
      "learning_rate": 3.0592634589142405e-05,
      "loss": 1.0642,
      "step": 2120
    },
    {
      "epoch": 0.6521407892731982,
      "grad_norm": 0.7784501910209656,
      "learning_rate": 2.9667771715455606e-05,
      "loss": 1.1272,
      "step": 2140
    },
    {
      "epoch": 0.6582355630047234,
      "grad_norm": 0.7816513776779175,
      "learning_rate": 2.8751170294141415e-05,
      "loss": 1.0703,
      "step": 2160
    },
    {
      "epoch": 0.6643303367362486,
      "grad_norm": 0.4358949363231659,
      "learning_rate": 2.784320276145619e-05,
      "loss": 1.0775,
      "step": 2180
    },
    {
      "epoch": 0.6704251104677739,
      "grad_norm": 0.6523589491844177,
      "learning_rate": 2.6944238045508708e-05,
      "loss": 1.0945,
      "step": 2200
    },
    {
      "epoch": 0.6704251104677739,
      "eval_loss": 1.0030755996704102,
      "eval_runtime": 238.691,
      "eval_samples_per_second": 13.75,
      "eval_steps_per_second": 1.722,
      "step": 2200
    },
    {
      "epoch": 0.6765198841992991,
      "grad_norm": 0.6550147533416748,
      "learning_rate": 2.605464141635599e-05,
      "loss": 1.0643,
      "step": 2220
    },
    {
      "epoch": 0.6826146579308243,
      "grad_norm": 0.851650059223175,
      "learning_rate": 2.5174774337585764e-05,
      "loss": 1.1264,
      "step": 2240
    },
    {
      "epoch": 0.6887094316623495,
      "grad_norm": 0.6607635617256165,
      "learning_rate": 2.4304994319445536e-05,
      "loss": 1.0119,
      "step": 2260
    },
    {
      "epoch": 0.6948042053938748,
      "grad_norm": 0.596990168094635,
      "learning_rate": 2.344565477357781e-05,
      "loss": 0.9935,
      "step": 2280
    },
    {
      "epoch": 0.7008989791254,
      "grad_norm": 0.7906503677368164,
      "learning_rate": 2.2597104869420928e-05,
      "loss": 1.0315,
      "step": 2300
    },
    {
      "epoch": 0.7008989791254,
      "eval_loss": 1.0020051002502441,
      "eval_runtime": 238.7567,
      "eval_samples_per_second": 13.746,
      "eval_steps_per_second": 1.721,
      "step": 2300
    },
    {
      "epoch": 0.7069937528569252,
      "grad_norm": 0.6774060726165771,
      "learning_rate": 2.17596893923334e-05,
      "loss": 1.0719,
      "step": 2320
    },
    {
      "epoch": 0.7130885265884505,
      "grad_norm": 0.4740222096443176,
      "learning_rate": 2.0933748603499788e-05,
      "loss": 1.012,
      "step": 2340
    },
    {
      "epoch": 0.7191833003199756,
      "grad_norm": 0.5175195336341858,
      "learning_rate": 2.011961810167462e-05,
      "loss": 0.922,
      "step": 2360
    },
    {
      "epoch": 0.7252780740515008,
      "grad_norm": 0.47972220182418823,
      "learning_rate": 1.931762868682098e-05,
      "loss": 1.0957,
      "step": 2380
    },
    {
      "epoch": 0.731372847783026,
      "grad_norm": 0.45702508091926575,
      "learning_rate": 1.852810622569882e-05,
      "loss": 1.0088,
      "step": 2400
    },
    {
      "epoch": 0.731372847783026,
      "eval_loss": 1.0006688833236694,
      "eval_runtime": 238.8283,
      "eval_samples_per_second": 13.742,
      "eval_steps_per_second": 1.721,
      "step": 2400
    },
    {
      "epoch": 0.7374676215145513,
      "grad_norm": 0.7394722700119019,
      "learning_rate": 1.7751371519457864e-05,
      "loss": 1.0007,
      "step": 2420
    },
    {
      "epoch": 0.7435623952460765,
      "grad_norm": 0.9313046336174011,
      "learning_rate": 1.698774017328867e-05,
      "loss": 0.872,
      "step": 2440
    },
    {
      "epoch": 0.7496571689776017,
      "grad_norm": 0.8447253704071045,
      "learning_rate": 1.6237522468184917e-05,
      "loss": 0.9154,
      "step": 2460
    },
    {
      "epoch": 0.7557519427091269,
      "grad_norm": 0.6965742111206055,
      "learning_rate": 1.5501023234869205e-05,
      "loss": 1.0633,
      "step": 2480
    },
    {
      "epoch": 0.7618467164406522,
      "grad_norm": 0.43911412358283997,
      "learning_rate": 1.4778541729933237e-05,
      "loss": 0.9494,
      "step": 2500
    },
    {
      "epoch": 0.7618467164406522,
      "eval_loss": 0.9995960593223572,
      "eval_runtime": 238.8006,
      "eval_samples_per_second": 13.744,
      "eval_steps_per_second": 1.721,
      "step": 2500
    },
    {
      "epoch": 0.7679414901721774,
      "grad_norm": 0.6133508682250977,
      "learning_rate": 1.4070371514243047e-05,
      "loss": 1.0288,
      "step": 2520
    },
    {
      "epoch": 0.7740362639037026,
      "grad_norm": 0.7732208371162415,
      "learning_rate": 1.3376800333658391e-05,
      "loss": 0.8546,
      "step": 2540
    },
    {
      "epoch": 0.7801310376352278,
      "grad_norm": 1.0519835948944092,
      "learning_rate": 1.2698110002115004e-05,
      "loss": 0.9119,
      "step": 2560
    },
    {
      "epoch": 0.786225811366753,
      "grad_norm": 0.6356686353683472,
      "learning_rate": 1.2034576287117128e-05,
      "loss": 1.074,
      "step": 2580
    },
    {
      "epoch": 0.7923205850982782,
      "grad_norm": 1.1032582521438599,
      "learning_rate": 1.138646879768685e-05,
      "loss": 0.9731,
      "step": 2600
    },
    {
      "epoch": 0.7923205850982782,
      "eval_loss": 0.9986449480056763,
      "eval_runtime": 238.6758,
      "eval_samples_per_second": 13.751,
      "eval_steps_per_second": 1.722,
      "step": 2600
    },
    {
      "epoch": 0.7984153588298034,
      "grad_norm": 0.5595724582672119,
      "learning_rate": 1.0754050874815663e-05,
      "loss": 1.0482,
      "step": 2620
    },
    {
      "epoch": 0.8045101325613286,
      "grad_norm": 0.45296740531921387,
      "learning_rate": 1.0137579484463039e-05,
      "loss": 1.1085,
      "step": 2640
    },
    {
      "epoch": 0.8106049062928539,
      "grad_norm": 0.6067918539047241,
      "learning_rate": 9.537305113145245e-06,
      "loss": 0.9342,
      "step": 2660
    },
    {
      "epoch": 0.8166996800243791,
      "grad_norm": 0.518430769443512,
      "learning_rate": 8.953471666156843e-06,
      "loss": 0.9853,
      "step": 2680
    },
    {
      "epoch": 0.8227944537559043,
      "grad_norm": 0.5604257583618164,
      "learning_rate": 8.386316368466401e-06,
      "loss": 1.0374,
      "step": 2700
    },
    {
      "epoch": 0.8227944537559043,
      "eval_loss": 0.9979334473609924,
      "eval_runtime": 238.707,
      "eval_samples_per_second": 13.749,
      "eval_steps_per_second": 1.722,
      "step": 2700
    },
    {
      "epoch": 0.8288892274874295,
      "grad_norm": 0.4485873878002167,
      "learning_rate": 7.836069668326518e-06,
      "loss": 1.0811,
      "step": 2720
    },
    {
      "epoch": 0.8349840012189548,
      "grad_norm": 0.47224161028862,
      "learning_rate": 7.302955143637419e-06,
      "loss": 1.0992,
      "step": 2740
    },
    {
      "epoch": 0.84107877495048,
      "grad_norm": 0.6904169917106628,
      "learning_rate": 6.787189411102057e-06,
      "loss": 1.1204,
      "step": 2760
    },
    {
      "epoch": 0.8471735486820052,
      "grad_norm": 0.5948818325996399,
      "learning_rate": 6.288982038209795e-06,
      "loss": 1.0008,
      "step": 2780
    },
    {
      "epoch": 0.8532683224135303,
      "grad_norm": 0.6358321905136108,
      "learning_rate": 5.808535458084291e-06,
      "loss": 1.0939,
      "step": 2800
    },
    {
      "epoch": 0.8532683224135303,
      "eval_loss": 0.9974309206008911,
      "eval_runtime": 238.6689,
      "eval_samples_per_second": 13.751,
      "eval_steps_per_second": 1.722,
      "step": 2800
    },
    {
      "epoch": 0.8593630961450556,
      "grad_norm": 0.692582905292511,
      "learning_rate": 5.346044887230306e-06,
      "loss": 1.0787,
      "step": 2820
    },
    {
      "epoch": 0.8654578698765808,
      "grad_norm": 0.760781466960907,
      "learning_rate": 4.901698246212683e-06,
      "loss": 0.947,
      "step": 2840
    },
    {
      "epoch": 0.871552643608106,
      "grad_norm": 0.5536001920700073,
      "learning_rate": 4.475676083299912e-06,
      "loss": 0.9879,
      "step": 2860
    },
    {
      "epoch": 0.8776474173396313,
      "grad_norm": 0.6471657752990723,
      "learning_rate": 4.068151501103268e-06,
      "loss": 0.9543,
      "step": 2880
    },
    {
      "epoch": 0.8837421910711565,
      "grad_norm": 0.520556628704071,
      "learning_rate": 3.6792900862411493e-06,
      "loss": 0.9287,
      "step": 2900
    },
    {
      "epoch": 0.8837421910711565,
      "eval_loss": 0.997126579284668,
      "eval_runtime": 238.8098,
      "eval_samples_per_second": 13.743,
      "eval_steps_per_second": 1.721,
      "step": 2900
    },
    {
      "epoch": 0.8898369648026817,
      "grad_norm": 0.5625708103179932,
      "learning_rate": 3.309249842057499e-06,
      "loss": 1.0987,
      "step": 2920
    },
    {
      "epoch": 0.8959317385342069,
      "grad_norm": 1.0274107456207275,
      "learning_rate": 2.9581811244213333e-06,
      "loss": 1.1366,
      "step": 2940
    },
    {
      "epoch": 0.9020265122657322,
      "grad_norm": 0.6554673910140991,
      "learning_rate": 2.6262265806337727e-06,
      "loss": 1.0265,
      "step": 2960
    },
    {
      "epoch": 0.9081212859972574,
      "grad_norm": 0.45174482464790344,
      "learning_rate": 2.3135210914671026e-06,
      "loss": 0.9487,
      "step": 2980
    },
    {
      "epoch": 0.9142160597287826,
      "grad_norm": 0.44478774070739746,
      "learning_rate": 2.0201917163596427e-06,
      "loss": 1.0154,
      "step": 3000
    },
    {
      "epoch": 0.9142160597287826,
      "eval_loss": 0.9968785643577576,
      "eval_runtime": 238.6355,
      "eval_samples_per_second": 13.753,
      "eval_steps_per_second": 1.722,
      "step": 3000
    },
    {
      "epoch": 0.9203108334603077,
      "grad_norm": 0.49720048904418945,
      "learning_rate": 1.7463576417885209e-06,
      "loss": 0.9865,
      "step": 3020
    },
    {
      "epoch": 0.926405607191833,
      "grad_norm": 0.6112064123153687,
      "learning_rate": 1.4921301328415572e-06,
      "loss": 1.0818,
      "step": 3040
    },
    {
      "epoch": 0.9325003809233582,
      "grad_norm": 0.6969384551048279,
      "learning_rate": 1.257612488007587e-06,
      "loss": 0.8004,
      "step": 3060
    },
    {
      "epoch": 0.9385951546548834,
      "grad_norm": 0.6523330211639404,
      "learning_rate": 1.0428999972040054e-06,
      "loss": 0.9362,
      "step": 3080
    },
    {
      "epoch": 0.9446899283864086,
      "grad_norm": 0.6761346459388733,
      "learning_rate": 8.480799030582187e-07,
      "loss": 0.9903,
      "step": 3100
    },
    {
      "epoch": 0.9446899283864086,
      "eval_loss": 0.9967593550682068,
      "eval_runtime": 238.7276,
      "eval_samples_per_second": 13.748,
      "eval_steps_per_second": 1.722,
      "step": 3100
    },
    {
      "epoch": 0.9507847021179339,
      "grad_norm": 0.5761563777923584,
      "learning_rate": 6.732313654589594e-07,
      "loss": 1.1088,
      "step": 3120
    },
    {
      "epoch": 0.9568794758494591,
      "grad_norm": 0.5696524381637573,
      "learning_rate": 5.184254293918444e-07,
      "loss": 0.977,
      "step": 3140
    },
    {
      "epoch": 0.9629742495809843,
      "grad_norm": 0.6466020345687866,
      "learning_rate": 3.837249960721268e-07,
      "loss": 1.0423,
      "step": 3160
    },
    {
      "epoch": 0.9690690233125095,
      "grad_norm": 0.5189595222473145,
      "learning_rate": 2.691847973864792e-07,
      "loss": 1.0614,
      "step": 3180
    },
    {
      "epoch": 0.9751637970440348,
      "grad_norm": 0.5618249177932739,
      "learning_rate": 1.7485137365418346e-07,
      "loss": 1.053,
      "step": 3200
    },
    {
      "epoch": 0.9751637970440348,
      "eval_loss": 0.996751070022583,
      "eval_runtime": 238.7001,
      "eval_samples_per_second": 13.749,
      "eval_steps_per_second": 1.722,
      "step": 3200
    },
    {
      "epoch": 0.98125857077556,
      "grad_norm": 0.8391275405883789,
      "learning_rate": 1.0076305471674042e-07,
      "loss": 1.0413,
      "step": 3220
    },
    {
      "epoch": 0.9873533445070852,
      "grad_norm": 0.7232685685157776,
      "learning_rate": 4.6949944363550156e-08,
      "loss": 1.0794,
      "step": 3240
    },
    {
      "epoch": 0.9934481182386103,
      "grad_norm": 0.5276363492012024,
      "learning_rate": 1.3433908100046744e-08,
      "loss": 0.9994,
      "step": 3260
    },
    {
      "epoch": 0.9995428919701356,
      "grad_norm": 0.678194522857666,
      "learning_rate": 2.2856426326045565e-10,
      "loss": 1.0623,
      "step": 3280
    }
  ],
  "logging_steps": 20,
  "max_steps": 3282,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.9395767066624e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
